{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate, zeros\n",
    "from scipy.linalg import toeplitz\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib as mat\n",
    "mat.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)    # reproducible\n",
    "mat.use(\"TkAgg\")\n",
    "\n",
    "hidden_siz = 50\n",
    "hidden_lay = 1\n",
    "\n",
    "LR = 0.02           # learning rate\n",
    "class LSNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSNN1, self).__init__()\n",
    "        self.lstm = nn.LSTM(  \n",
    "            input_size=1,\n",
    "            hidden_size=hidden_siz,    \n",
    "            num_layers=hidden_lay,      \n",
    "            batch_first=True,\n",
    "\n",
    "        )\n",
    "        self.hidden = (torch.autograd.Variable(torch.zeros(hidden_lay, 1, hidden_siz)),torch.autograd.Variable(torch.zeros(hidden_lay, 1, hidden_siz)))\n",
    "        self.out = nn.Linear(hidden_siz, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, output_size)\n",
    "        r_out,self.hidden= self.lstm(x,self.hidden)\n",
    "        self.hidden=(Variable(self.hidden[0]),Variable(self.hidden[1]))\n",
    "        outs = []\n",
    "        #print(r_out.size())\n",
    "        for time_step in range(33):\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "    \n",
    "class LSNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSNN2, self).__init__()\n",
    "        self.lstm = nn.LSTM(  \n",
    "            input_size=1,\n",
    "            hidden_size=hidden_siz,    \n",
    "            num_layers=hidden_lay,      \n",
    "            batch_first=True,\n",
    "\n",
    "        )\n",
    "        self.hidden = (torch.autograd.Variable(torch.zeros(hidden_lay, 1, hidden_siz)),torch.autograd.Variable(torch.zeros(hidden_lay, 1, hidden_siz)))\n",
    "        self.out = nn.Linear(hidden_siz, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, output_size)\n",
    "        r_out,self.hidden= self.lstm(x,self.hidden)\n",
    "        self.hidden=(Variable(self.hidden[0]),Variable(self.hidden[1]))\n",
    "        outs = []\n",
    "        for time_step in range(100):\n",
    "            if(time_step>=33 and time_step<66):\n",
    "                outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1)\n",
    "\n",
    "class LSNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSNN3, self).__init__()\n",
    "        self.lstm = nn.LSTM(  \n",
    "            input_size=1,\n",
    "            hidden_size=hidden_siz,    \n",
    "            num_layers=hidden_lay,      \n",
    "            batch_first=True,\n",
    "\n",
    "        )\n",
    "        self.hidden = (torch.autograd.Variable(torch.zeros(hidden_lay, 1, hidden_siz)),torch.autograd.Variable(torch.zeros(hidden_lay, 1, hidden_siz)))\n",
    "        self.out = nn.Linear(hidden_siz, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, output_size)\n",
    "        r_out,self.hidden= self.lstm(x,self.hidden)\n",
    "        self.hidden=(Variable(self.hidden[0]),Variable(self.hidden[1]))\n",
    "        outs = []\n",
    "        for time_step in range(67):\n",
    "            if(time_step>=33 and time_step<67):\n",
    "                outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-99a49535835e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mprediction_list1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mprediction2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstmNN2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;31m#print(\"x2 \",x2.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m#print(\"prediction2 \",prediction2.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-3372734e2f44>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# h_state (n_layers, batch, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# r_out (batch, time_step, output_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mr_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 522\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    523\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstmNN1 = LSNN1()\n",
    "lstmNN2 = LSNN2()\n",
    "lstmNN3 = LSNN3()\n",
    "optimizer1 = torch.optim.Adam(lstmNN1.parameters(), lr=LR)  # optimize all rnn parameters\n",
    "optimizer2 = torch.optim.Adam(lstmNN2.parameters(), lr=LR)\n",
    "optimizer3 = torch.optim.Adam(lstmNN3.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "\n",
    "loss_list1 = []\n",
    "loss_list2 = []\n",
    "loss_list3 = []\n",
    "prediction_list1 = []\n",
    "prediction_list2 = []\n",
    "prediction_list3 = []\n",
    "\n",
    "steps = np.linspace(0, 100, 100, dtype=np.float32)\n",
    "\n",
    "for step in range(98):\n",
    "    \n",
    "    if step == 0:\n",
    "        x_np1 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step: step + 1, :33]\n",
    "        x_np2 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step: step + 1, 33: 66]      \n",
    "        x_np3 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step: step + 1, 66:]\n",
    "        y_np1 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step + 1: step + 2, :33]\n",
    "        y_np2 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step + 1: step + 2, 33: 66]\n",
    "        y_np3 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step + 1: step + 2, 66:]\n",
    "        x1 = Variable(torch.from_numpy(np.append(x_np1,x_np2)).float())  # shape (batch, time_step, input_size)\n",
    "        y1 = Variable(torch.from_numpy(y_np1).float())\n",
    "        x2 = Variable(torch.from_numpy(np.append(np.append(x_np1,x_np2),x_np3)).float())  # shape (batch, time_step, input_size)\n",
    "        y2 = Variable(torch.from_numpy(y_np2).float())\n",
    "        x3 = Variable(torch.from_numpy(np.append(x_np2,x_np3)).float())  # shape (batch, time_step, input_size)\n",
    "        y3 = Variable(torch.from_numpy(y_np3).float())\n",
    "    else:\n",
    "        y_np1 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step + 1: step + 2, :33]\n",
    "        y_np2 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step + 1: step + 2, 33: 66]\n",
    "        y_np3 = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step + 1: step + 2, 66:]\n",
    "        x1 = Variable(torch.from_numpy(np.append(prediction1.data.view(33).numpy(),prediction2.data.view(33).numpy())).float())  # shape (batch, time_step, input_size)\n",
    "        y1 = Variable(torch.from_numpy(y_np1).float())\n",
    "        x2 = Variable(torch.from_numpy(np.append(np.append(prediction1.data.view(33).numpy(),prediction2.data.view(33).numpy()),prediction3.data.view(34).numpy())).float())  # shape (batch, time_step, input_size)\n",
    "        y2 = Variable(torch.from_numpy(y_np2).float())\n",
    "        x3 = Variable(torch.from_numpy(np.append(prediction2.data.view(33).numpy(),prediction3.data.view(34).numpy())).float())  # shape (batch, time_step, input_size)\n",
    "        y3 = Variable(torch.from_numpy(y_np3).float())\n",
    "    \n",
    "    #print(x_np1.size, x_np2.size,x_np3.size)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    x1 = x1.view(1,66,1)\n",
    "    y1 = y1.view(1,33,1)\n",
    "    x2 = x2.view(1,100,1)\n",
    "    y2 = y2.view(1,33,1)\n",
    "    x3 = x3.view(1,67,1)\n",
    "    y3 = y3.view(1,34,1)\n",
    "    \n",
    "    prediction1 = lstmNN1(x1)\n",
    "    \n",
    "    prediction_list1.append(prediction1.data.view(33).numpy())    \n",
    "    prediction2 = lstmNN2(x2)\n",
    "    #print(\"x2 \",x2.size())\n",
    "    #print(\"prediction2 \",prediction2.size())\n",
    "    prediction_list2.append(prediction2.data.view(33).numpy())    \n",
    "    prediction3 = lstmNN3(x3)\n",
    "    prediction_list3.append(prediction3.data.view(34).numpy())\n",
    "\n",
    "    loss1 = loss_func(prediction1, y1)\n",
    "    loss_list1.append(loss1)\n",
    "    loss2 = loss_func(prediction2, y2)\n",
    "    loss_list2.append(loss2)\n",
    "    loss3 = loss_func(prediction3, y3)\n",
    "    loss_list3.append(loss3)\n",
    "    \n",
    "    #train_loss += loss*X.size(0)\n",
    "    \n",
    "    optimizer1.zero_grad()               # clear gradients for this training step\n",
    "    optimizer2.zero_grad()\n",
    "    optimizer3.zero_grad()\n",
    "    \n",
    "    loss1.backward()                     # backpropagation, compute gradients\n",
    "    loss2.backward()\n",
    "    loss3.backward()\n",
    "    \n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    optimizer3.step()\n",
    "\n",
    "    for i in range(20):\n",
    "    #while(loss_func(prediction1, x1[:,:33,:]) > 0.01 or loss_func(prediction2, x2[:,33: 66,:])>0.01 or loss_func(prediction3, x3[:,66: ,:])>0.01):\n",
    "        x1= Variable(torch.from_numpy(np.append(x1[:,:33,:].data.view(33).numpy(),prediction2.data.view(33).numpy())).float())\n",
    "        x2= Variable(torch.from_numpy(np.append(np.append(prediction1.data.view(33).numpy(),x2[:,33:66,:].data.view(33).numpy()),prediction3.data.view(34).numpy())).float())\n",
    "        x3= Variable(torch.from_numpy(np.append(prediction2.data.view(33).numpy(),x3[:,33:,:].data.view(34).numpy())).float())\n",
    "        x1 = x1.view(1,66,1)\n",
    "        x2 = x2.view(1,100,1)\n",
    "        x3 = x3.view(1,67,1)\n",
    "        #print(loss_func(prediction1, x1[:,:33,:]))\n",
    "        prediction1 = lstmNN1(x1)\n",
    "    \n",
    "        prediction_list1.append(prediction1.data.view(33).numpy())    \n",
    "        prediction2 = lstmNN2(x2)\n",
    "        #print(\"x2 \",x2.size())\n",
    "        #print(\"prediction2 \",prediction2.size())\n",
    "        prediction_list2.append(prediction2.data.view(33).numpy())    \n",
    "        prediction3 = lstmNN3(x3)\n",
    "        prediction_list3.append(prediction3.data.view(34).numpy())\n",
    "\n",
    "        loss1 = loss_func(prediction1, y1)\n",
    "        loss_list1.append(loss1)\n",
    "        loss2 = loss_func(prediction2, y2)\n",
    "        loss_list2.append(loss2)\n",
    "        loss3 = loss_func(prediction3, y3)\n",
    "        loss_list3.append(loss3)\n",
    "    \n",
    "        #train_loss += loss*X.size(0)\n",
    "    \n",
    "        optimizer1.zero_grad()               # clear gradients for this training step\n",
    "        optimizer2.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "    \n",
    "        loss1.backward()                     # backpropagation, compute gradients\n",
    "        loss2.backward()\n",
    "        loss3.backward()\n",
    "    \n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        optimizer3.step()\n",
    "\n",
    "        # apply gradients\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.figsize=(20, 10)\n",
    "    plt.ion()\n",
    "    plt.title(step,fontsize=24)\n",
    "    plt.plot(steps, np.append(np.append(y_np1,y_np2),y_np3).flatten(), 'r-')\n",
    "    plt.plot(steps, np.append(np.append(prediction1.data.numpy(),prediction2.data.numpy()),prediction3.data.numpy()).flatten(), 'b-')\n",
    "    #plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.01)\n",
    "    plt.clf()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-442f6897174e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m94\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(steps[:94], loss_list, label = 'Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE9lJREFUeJzt3X+wXHd53/H3s7tXEsi/wBIh1Q8kD6KJ6qlj5kZxYg+4hAyym7E6HdKxmwDtuNFMBpOQMM04Q8ch7h9tUqY0aRRaTyAklOA4TiZoGKWGIW4IaexKrsE/5MjIIrEutmuBQcbY1t2z+/SPc+7Vcn0lXcu7d+9+9X7N3Nk9Z7/s9zkc3Y+f+90fJzITSVJZWuMuQJI0fIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCdcU28bt263LJly7iml6SJdN99930jM9efadzYwn3Lli0cOHBgXNNL0kSKiL9fyjiXZSSpQIa7JBXIcJekAhnuklQgw12SCnTGcI+Ij0fE0xHx0Ckej4j4rYg4HBEPRMSbh1+mJOnlWErn/glg52kevwbY1vzsBj76ysuSJL0SZ3yfe2Z+MSK2nGbILuAPsr5e3z0RcVFEfH9mPjmkGiVpcmXCpz4FzzzD87MdPvTnP8J7f3ktb3jHD4x02mF8iGkDcHRge6bZ95Jwj4jd1N09mzdvHsLUkrTCPfoovOtd/CVv4UY+xmO8ka2v+yI/N+JwH8YLqrHIvkWvup2Zt2XmdGZOr19/xk/PStLEy+df4P18hKv5S3LLVu7+zLP83O/tGPm8w+jcZ4BNA9sbgSeG8LySNPEOPdbhN3k/737bUX5n7ybWrr1gWeYdRue+F3h3866ZK4DjrrdLUu2F7/YB+OdXHWPt2uWb94yde0R8GrgaWBcRM8CvAlMAmfnfgH3AtcBh4HngX4+qWEmaNNVsHe6dVYutYI/OUt4tc8MZHk/gvUOrSJIKMh/uU8v7mVE/oSpJI3SyczfcJakYhrskFWg+3Fe3l3Vew12SRsjOXZIKVHXrz3Qa7pJUkKrrsowkFaeabTp3w12SyjG35j612mUZSSrG/Jq7nbsklaOqDHdJKk53tr7trBnGl/AuneEuSSNk5y5JBaq69a2duyQVZL5zN9wlqRx27pJUoKqqb/36AUkqyHy4Ty3vlZgMd0kaoaqCoE9rmdPWcJekEap60KFa9nkNd0kaoaoKw12SSlP1oBO9ZZ/XcJekEbJzl6QCVb1gKgx3SSpK1QuXZSSpNK65S1KBur2W4S5JpakMd0kqT9ULOq3+ss9ruEvSCFV9X1CVpOJUvdbK7dwjYmdEHIqIwxFx8yKPb46IuyPi/oh4ICKuHX6pkjR5qn6LTqzAcI+INrAHuAbYDtwQEdsXDPt3wB2ZeTlwPfA7wy5UkiZR1V+5nfsO4HBmHsnMWeB2YNeCMQlc0Ny/EHhieCVK0uRayeG+ATg6sD3T7Bv0IeBnImIG2Ae8b7EniojdEXEgIg4cO3bsLMqVpMmyksN9scuH5ILtG4BPZOZG4FrgkxHxkufOzNsyczozp9evX//yq5WkCVNli057ZYb7DLBpYHsjL112uRG4AyAz/wZYA6wbRoGSNMlWcue+H9gWEVsjYhX1C6Z7F4x5HPhxgIj4Qepwd91F0jmvyjZTK7Fzz8wKuAm4C3iE+l0xD0fErRFxXTPsA8DPRsRXgE8D/yozFy7dSNI5p+7clz8OO0sZlJn7qF8oHdx3y8D9g8CVwy1NkiZflW067eUPdz+hKkkj1M2O4S5JpbFzl6QCGe6SVCDDXZIKVNGh0zHcJakodee+/PMa7pI0QnbuklSgOtyXf17DXZJGpd+vw91lGUkqR1Y9enbuklSW3okKwHCXpJJULzbhPrXYZTFGy3CXpBGZC/epKd8tI0nFqE70AOh07NwlqRguy0hSgbovNp371PLPbbhL0oi4LCNJBZoPd5dlJKkc8+G+avmj1nCXpBGpZvuAnbskFcVlGUkq0Hzn7rKMJJXDzl2SCmTnLkkFMtwlqUCGuyQVaC7cp1Yb7pJUDDt3SSrQfLivXv6LqBrukjQi3dn6Ih0rtnOPiJ0RcSgiDkfEzacY8y8i4mBEPBwRfzjcMiVp8lTdJtzH0Lmf8bKtEdEG9gA/AcwA+yNib2YeHBizDfgV4MrM/FZEvG5UBUvSpJgP9zXLf4XspXTuO4DDmXkkM2eB24FdC8b8LLAnM78FkJlPD7dMSZo8Jzv3lbksswE4OrA90+wb9CbgTRHx1xFxT0TsHFaBkjSpTob78nfuS5lxsS9FWHgp7w6wDbga2Aj8VURcmpnf/p4nitgN7AbYvHnzyy5WkibJONfcl9K5zwCbBrY3Ak8sMuYzmdnNzK8Bh6jD/ntk5m2ZOZ2Z0+vXrz/bmiVpIqz0cN8PbIuIrRGxCrge2LtgzJ8B/wQgItZRL9McGWahkjRpqqq+XZHhnpkVcBNwF/AIcEdmPhwRt0bEdc2wu4BvRsRB4G7g32bmN0dVtCRNgnG+W2ZJM2bmPmDfgn23DNxP4JeaH0kSA537Cn0rpCTpLBjuklSg+XBfqV8/IEl6+aoKWvRojSFpDXdJGpGqgg7VWOY23CVpRAx3SSpQtxd06I1lbsNdkkakqoJO2LlLUlGqHnTCzl2SilL1wnCXpNJUrrlLUnmqXtBpGe6SVJSq13JZRpJK45q7JBWo6ged6I9lbsNdkkak6rVcc5ek0lT9Fp2WnbskFaXqB1N27pJUFjt3SSqQ4S5JBer224a7JJWm6rfptHIscxvukjQiVbbotO3cJakoVdq5S1Jxqn6bTttwl6SiuCwjSQWq0s5dkopjuEtSgars0GmPZ27DXZJGpMLOXZKKU2WbTmc8cy8p3CNiZ0QciojDEXHzaca9MyIyIqaHV6IkTaaKzsrt3COiDewBrgG2AzdExPZFxp0P/Dxw77CLlKRJVNFhamqFhjuwAzicmUcycxa4Hdi1yLh/D/wG8OIQ65OkiVV37uOZeynhvgE4OrA90+ybFxGXA5sy87NDrE2SJlb2+vTorOg191hk3/zfGRHRAj4CfOCMTxSxOyIORMSBY8eOLb1KSZow1YsVwIoO9xlg08D2RuCJge3zgUuB/xURfwdcAexd7EXVzLwtM6czc3r9+vVnX7UkrXDz4T41nvmXEu77gW0RsTUiVgHXA3vnHszM45m5LjO3ZOYW4B7gusw8MJKKJWkCnOzcF1v8GL0zhntmVsBNwF3AI8AdmflwRNwaEdeNukBJmkTVifrC2ONallnStJm5D9i3YN8tpxh79SsvS5Im28llmRXauUuSXr75zt1wl6RynAz38cxvuEvSCNi5S1KBTob7eGLWcJekEbBzl6QCVbP1tVMNd0kqyFznPrXKcJekYswvy6xyzV2SijG/LGO4S1I5uicMd0kqjp27JBVoPtxXG+6SVIyTnft4rrNnuEvSCFTd+oJ1LstIUkFOLsvYuUtSMezcJalA8+Fu5y5J5ai6LstIUnHs3CWpQFW3vjXcJakgdu6SVKC5cJ96VWcs8xvukjQCVVXf2rlLUkG6c2vua+zcJakY85274S5J5ZgL97ZfHCZJ5agqaNGj1fHrBySpGFUFHaqxzW+4S9IIGO6SVKCqFys/3CNiZ0QciojDEXHzIo//UkQcjIgHIuILEfGG4ZcqSZOjqqATvbHNf8Zwj4g2sAe4BtgO3BAR2xcMux+Yzsx/DNwJ/MawC5WkSVJ37is43IEdwOHMPJKZs8DtwK7BAZl5d2Y+32zeA2wcbpmSNFmqHnRiZS/LbACODmzPNPtO5Ubgz19JUZI06apejHVZZikfnYpF9uWiAyN+BpgG3nqKx3cDuwE2b968xBIlafKMO9yX0rnPAJsGtjcCTywcFBFvBz4IXJeZJxZ7osy8LTOnM3N6/fr1Z1OvJE2EqtdiaoWH+35gW0RsjYhVwPXA3sEBEXE58N+pg/3p4ZcpSZOl6gWd1goO98ysgJuAu4BHgDsy8+GIuDUirmuG/SfgPOCPI+LLEbH3FE8nSeeEqr/y19zJzH3AvgX7bhm4//Yh1yVJE63ba9Np9cc2v59QlaQRqDt3w12SilL1Wyt7zV2S9PJVvZbLMpJUmioNd0kqTr0ss+jnPZeF4S5JI1CHu527JBWl6rfptA13SSpKvebusowkFaXKNp224S5JRanD3WUZSSpKveZu5y5JRaloM2W4S1JZXHOXpAJ1s0OnY7hLUlGq7NBpj29+w12SRqDCZRlJKk5Fh86SLoc0Goa7JI2A4S5Jhen3kj5tw12SStLr1p9MNdwlqSDVixVguEtSUQx3SSpQdaIJ96kYWw2GuyQNWfViD7Bzl6SiVCeacLdzl6RyzIX71NT4ajDcJWnI5l9QtXOXpHK4LCNJBerOvaC6ynCXpGKc7NzHF7GGuyQNWTXbfP3AqhUe7hGxMyIORcThiLh5kcdXR8QfNY/fGxFbhl2oJE2KiQj3iGgDe4BrgO3ADRGxfcGwG4FvZeYbgY8Avz7sQiVpUqyEF1SX8vmpHcDhzDwCEBG3A7uAgwNjdgEfau7fCfx2RERmDv0yJJ/78AP8yf94garfottvk8CrOl3WTnXptHo8/uxFfO34a3nmhVfx7kvv5xen/4rzV8+e9jmf705x31MbeOK5C/jO7GqePbGafgarOz1WtSs60acVSQRkQrffpttvUfXbVP0WVb9FL196Euf2RCQLHx3f9Vmkc1Mu9jsaSSuSdiSdVp9Oq8dUq8+qdv27f/Ga57nsdU/y+vOeW/I8M89ewH/cuxOACy8Y32/6UsJ9A3B0YHsG+JFTjcnMKiKOAxcD3xgcFBG7gd0AmzdvPquCv/q/j/GZr/wjpqjoUBEkL7CG77KWLlNsjK+zlUNcBPzql36C//qlH+Lm9od5R+vzvDEeY02c4Jl8DX/d/1G+mFfxpf6PcV++mS6rzqoeSeX7Pp7isniQy1oPcFk8yBvicb6dF/IN1vEdzuN8nuNCjvNYXsKv9d5HRYf/8Opb2XHNT4+t5jhTcx0RPwW8IzP/TbP9LmBHZr5vYMzDzZiZZvuxZsw3T/W809PTeeDAgSEcwqnt3w8f/CB8/vNzdcLrXw9PPVV34KtWwY4dcNVVcOWVcMklcMEFcP750GrB7CycOAFVVY/v9+vnmJqqfzqdk7etVv3YnLn/WzO/9/7gmBjfX2zSOWnh7+jc73W/X/+eV1X9e9/t1rdPPglf+Qrcfz98+ctw8GC9/3R27oQ9e+o8Gc0xxH2ZOX2mcUvp3GeATQPbG4EnTjFmJiI6wIXAM0usdWR++Ifhc5+Dhx6CBx+ERx+FI0dg2zZ4y1vqYF+zZtxVSlqp3vQmeOtbT253u3DoEMzMwMUXw7p1cN558NxzcPx4Peayy1ZG47aUcN8PbIuIrcDXgeuBf7lgzF7gPcDfAO8E/mIU6+1n69JL6x9JeiWmphbPk/Xrx1PP6Zwx3Js19JuAu4A28PHMfDgibgUOZOZe4GPAJyPiMHXHfv0oi5Yknd6Svm04M/cB+xbsu2Xg/ovATw23NEnS2fITqpJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAZ/z6gZFNHHEM+Puz/J+vY8H31pwDPOZzg8d8bnglx/yGzDzjx6bGFu6vREQcWMp3K5TEYz43eMznhuU4ZpdlJKlAhrskFWhSw/22cRcwBh7zucFjPjeM/Jgncs1dknR6k9q5S5JOY+LCPSJ2RsShiDgcETePu55RiIhNEXF3RDwSEQ9HxC80+18bEZ+PiK82t68Zd63DFBHtiLg/Ij7bbG+NiHub4/2jiCjqWogRcVFE3BkRf9uc6x89B87xLzb/ph+KiE9HxJrSznNEfDwino6Ihwb2LXpeo/ZbTZ49EBFvHlYdExXuEdEG9gDXANuBGyJi+3irGokK+EBm/iBwBfDe5jhvBr6QmduALzTbJfkF4JGB7V8HPtIc77eAG8dS1ej8JvA/M/MHgMuoj73YcxwRG4CfB6Yz81Lq60NcT3nn+RPAzgX7TnVerwG2NT+7gY8Oq4iJCndgB3A4M49k5ixwO7BrzDUNXWY+mZn/t7n/Hepf+g3Ux/r7zbDfB/7ZeCocvojYCPxT4Heb7QDeBtzZDCnteC8A3kJ9oRsyczYzv03B57jRAV7VXI7z1cCTFHaeM/OLvPQyo6c6r7uAP8jaPcBFEfH9w6hj0sJ9A3B0YHum2VesiNgCXA7cC3xfZj4J9X8AgNeNr7Kh+y/ALwP9Zvti4NuZWTXbpZ3rS4BjwO81S1G/GxFrKfgcZ+bXgQ8Dj1OH+nHgPso+z3NOdV5HlmmTFu6LXXa22Lf7RMR5wJ8A78/MZ8ddz6hExE8CT2fmfYO7Fxla0rnuAG8GPpqZlwPfpaAlmMU068y7gK3APwDWUi9LLFTSeT6Tkf07n7RwnwE2DWxvBJ4YUy0jFRFT1MH+qcz802b3/5v7k625fXpc9Q3ZlcB1EfF31Ettb6Pu5C9q/nyH8s71DDCTmfc223dSh32p5xjg7cDXMvNYZnaBPwV+jLLP85xTndeRZdqkhft+YFvz6voq6hdj9o65pqFr1ps/BjySmf954KG9wHua++8BPrPctY1CZv5KZm7MzC3U5/QvMvOngbuBdzbDijlegMx8CjgaEf+w2fXjwEEKPceNx4ErIuLVzb/xuWMu9jwPONV53Qu8u3nXzBXA8bnlm1csMyfqB7gWeBR4DPjguOsZ0TFeRf2n2QPAl5ufa6nXob8AfLW5fe24ax3BsV8NfLa5fwnwf4DDwB8Dq8dd35CP9YeAA815/jPgNaWfY+DXgL8FHgI+Cawu7TwDn6Z+TaFL3ZnfeKrzSr0ss6fJswep30k0lDr8hKokFWjSlmUkSUtguEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVKD/DwsGaiZF8uCBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "loss_list = []\n",
    "prediction_list = []\n",
    "for step in range(10):\n",
    "    steps = np.linspace(0, 100, 100, dtype=np.float32)\n",
    "    \n",
    "    if step <6:\n",
    "        if step == 0:\n",
    "            x_np = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step: 5, :]\n",
    "            y_np = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[5:6, :] \n",
    "        else:\n",
    "            \n",
    "            x_np = concatenate([toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step: 5, :],\n",
    "                                np.array(prediction_list[:step])])\n",
    "            y_np = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step+5:step+6, :]\n",
    "        \n",
    "    else:\n",
    "        x_np = np.array(prediction_list[-5:])\n",
    "        y_np = toeplitz(concatenate([[1.], zeros(99)]),concatenate([[1.,1.,1.], zeros(97)]))[step+5:step+6, :]   \n",
    "    \n",
    "    #x_np = steps    # float32 for converting torch FloatTensor\n",
    "    #y_np = steps\n",
    "    x = Variable(torch.from_numpy(x_np).float())  # shape (batch, time_step, input_size)\n",
    "    y = Variable(torch.from_numpy(y_np).float())\n",
    "\n",
    "    x = x.permute(-1,0).view(1,100,5)\n",
    "    y = y.view(1,100,1)\n",
    "    with torch.no_grad():\n",
    "        prediction = lstmNN(x)\n",
    "        #print(\"pre \",prediction.data.size())\n",
    "        prediction_list.append(prediction.data.view(100).numpy())\n",
    "        #print(prediction_list)\n",
    "        loss = loss_func(prediction, y)     # cross entropy loss\n",
    "        loss_list.append(loss)\n",
    "    \n",
    "    #train_loss += loss*X.size(0)\n",
    "    \n",
    "    # apply gradients\n",
    "    plt.figsize=(20, 10)\n",
    "    plt.ion()\n",
    "    plt.title(step,fontsize=24)\n",
    "    plt.plot(steps, y_np.flatten(), 'r-')\n",
    "    plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n",
    "    #plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.5)\n",
    "    plt.clf()\n",
    "\n",
    "    plt.ioff()\n",
    "    #plt.show()\n",
    "plt.plot(steps, y_np.flatten(), 'r-')\n",
    "plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGmNJREFUeJzt3XuQXOV95vHv090jxMUCLCbBaIRnWLSxBcUlHovrUlsoCSJxkP+AYsDGcqwtarfQguPEKSlbwRtVcFllV7ApY1OyECGYsgCFssdGjnYXkS1TywoNl7UjZBWDuGgiJYy5CNt4kEbz2z/6zKhpndPdmhlppHmfT5WKc95+z5n3ND39zHt+53QrIjAzMytN9QDMzOzo4EAwMzPAgWBmZhkHgpmZAQ4EMzPLOBDMzAxwIJiZWcaBYGZmgAPBzMwylakewKE47bTTorOzc6qHYWZ2THnmmWd+ERHtzfodU4HQ2dlJX1/fVA/DzOyYIunVVvr5lJGZmQEOBDMzyzgQzMwMOMZqCGZm47Vv3z4GBgYYGhqa6qEcNjNnzqSjo4O2trZxbe9AMLMkDAwM8IEPfIDOzk4kTfVwJl1E8MYbbzAwMEBXV9e49uFTRmaWhKGhIWbPnj0twwBAErNnz57QDMiBYGbJmK5hMGqix5dEINz/f17hh/9v11QPw8zsqJZEIDy4+VU2/Gz3VA/DzBJ30kknTfUQGkoiEMqlEsMjMdXDMDM7qiURCJWS2O9AMLOj0KuvvsrChQs577zzWLhwIa+99hoAjzzyCOeeey7nn38+V1xxBQBbt25lwYIFXHDBBZx33nm8+OKLkzqWJC47LZfEvv0jUz0MMztK/PUPt/LCrncmdZ/zz5jFl/74nEPebtmyZXzmM59hyZIlrF27lltvvZXvf//7rFy5ko0bNzJnzhzefvttAO655x5uu+02PvWpT7F37172798/qceQxAyhrewZgpkdnZ566iluvPFGAG666SaefPJJAC677DI++9nP8p3vfGfsjf+SSy7hy1/+MqtWreLVV1/l+OOPn9SxJDNDcA3BzEaN5y/5I2X00tF77rmHzZs389hjj3HBBRfw/PPPc+ONN3LRRRfx2GOPcdVVV7FmzRquvPLKSfvZScwQKqWSZwhmdlS69NJLWbduHQAPPvggl19+OQAvvfQSF110EStXruS0005j586d7Nixg7POOotbb72Va665hp/+9KeTOpZ0ZgiuIZjZFHv33Xfp6OgYW//CF77AXXfdxec+9zm++tWv0t7ezn333QfAF7/4RV588UUigoULF3L++efzla98he9+97u0tbVx+umnc/vtt0/q+JIIhLayTxmZ2dQbGcn/w3TTpk0HtT366KMHta1YsYIVK1ZM+rhGJXHKqOzLTs3MmkoiECq+Mc3MrKkkAsE1BDOD6kdET2cTPb4kAqHiy07Nkjdz5kzeeOONaRsKo9+HMHPmzHHvo6WisqRFwDeAMrAmIr5S9/hxwN8DHwPeAK6PiFckzQbWAx8H/i4ilmX9TwAeAf4dsB/4YUQsH/dRNFHxjWlmyevo6GBgYIDBwcGpHsphM/qNaePVNBAklYG7gd8HBoAtknoj4oWabkuBtyLibEk9wCrgemAI+Cvg3Oxfra9FxBOSZgCPS7o6In487iNpwB9uZ2ZtbW3j/iaxVLRyymgB0B8ROyJiL7AOWFzXZzFwf7a8HlgoSRHx64h4kmowjImIdyPiiWx5L/AsMP5Ya6LiGoKZWVOtBMIcYGfN+kDWltsnIoaBPcDsVgYg6RTgj4HHW+k/Hv7oCjOz5loJhLzvZKt/d22lz8E7lirA94C7ImJHQZ+bJfVJ6hvvuT9/uJ2ZWXOtBMIAMLdmvQOo/z7KsT7Zm/zJwJst7Hs18GJEfL2oQ0SsjojuiOhub29vYZcHcw3BzKy5VgJhCzBPUldWAO4Beuv69AJLsuVrgU3R5NouSX9DNTg+f2hDPnT+ghwzs+aaXmUUEcOSlgEbqV52ujYitkpaCfRFRC9wL/CApH6qM4Oe0e0lvQLMAmZI+iTwB8A7wH8Dfg48m33c6zcjYs1kHtyo0Y+uiIixj5Y1M7P3a+k+hIjYAGyoa7u9ZnkIuK5g286C3R6xd+a2cvVHDY/E2LKZmb1fEncql0vVw/RpIzOzYkkEQqV0YIZgZmb5kgiE8mgg+OY0M7NCSQRCbQ3BzMzyJREIriGYmTWXRCC4hmBm1lwSgeAagplZc0kEQsU1BDOzptIIBNcQzMyaSiIQDpwyciCYmRVJIhAOFJVdQzAzK5JEIJRdQzAzayqJQGhzDcHMrKkkAsE1BDOz5pIIhAOXnbqGYGZWJIlAKPtOZTOzppIIhLEagk8ZmZkVSiIQPEMwM2suiUAYrSH4KiMzs2JJBELZN6aZmTWVRCCM1hB82amZWbGWAkHSIknbJfVLWp7z+HGSHsoe3yypM2ufLekJSb+S9M26bT4m6WfZNndJ0mQcUJ6yTxmZmTXVNBAklYG7gauB+cANkubXdVsKvBURZwN3Aquy9iHgr4A/z9n1t4GbgXnZv0XjOYBW+AtyzMyaa2WGsADoj4gdEbEXWAcsruuzGLg/W14PLJSkiPh1RDxJNRjGSPoQMCsinoqIAP4e+OREDqQR1xDMzJprJRDmADtr1geyttw+ETEM7AFmN9nnQJN9ThrXEMzMmmslEPLO7de/s7bSZ1z9Jd0sqU9S3+DgYINdFnMNwcysuVYCYQCYW7PeAewq6iOpApwMvNlknx1N9glARKyOiO6I6G5vb29huAdzDcHMrLlWAmELME9Sl6QZQA/QW9enF1iSLV8LbMpqA7kiYjfwS0kXZ1cXfQb4wSGPvkUHPu3UNQQzsyKVZh0iYljSMmAjUAbWRsRWSSuBvojoBe4FHpDUT3Vm0DO6vaRXgFnADEmfBP4gIl4A/gvwd8DxwI+zf4eFZwhmZs01DQSAiNgAbKhru71meQi4rmDbzoL2PuDcVgc6EZIol+QagplZA0ncqQzV00aeIZiZFUsmEColuYZgZtZAWoHgGYKZWaF0AqFccg3BzKyBZALBNQQzs8aSCQTXEMzMGksmEHzZqZlZY8kEQlu55FNGZmYNJBMIniGYmTWWTCBUSmKfawhmZoWSCQTPEMzMGksmECquIZiZNZROIHiGYGbWUDKBUL0xzTUEM7MiyQRC9cY0zxDMzIqkEwiuIZiZNZROILiGYGbWUDKB4A+3MzNrLJlA8IfbmZk1lk4g+PsQzMwaSicQfMrIzKyhZALBH11hZtZYS4EgaZGk7ZL6JS3Pefw4SQ9lj2+W1Fnz2Iqsfbukq2ra/1TSVkn/LOl7kmZOxgEV8YfbmZk11jQQJJWBu4GrgfnADZLm13VbCrwVEWcDdwKrsm3nAz3AOcAi4FuSypLmALcC3RFxLlDO+h02lbJnCGZmjbQyQ1gA9EfEjojYC6wDFtf1WQzcny2vBxZKUta+LiLei4iXgf5sfwAV4HhJFeAEYNfEDqWxSsk3ppmZNdJKIMwBdtasD2RtuX0iYhjYA8wu2jYi/gX4GvAasBvYExH/I++HS7pZUp+kvsHBwRaGm881BDOzxloJBOW01b+zFvXJbZd0KtXZQxdwBnCipE/n/fCIWB0R3RHR3d7e3sJw87mGYGbWWCuBMADMrVnv4ODTO2N9slNAJwNvNtj294CXI2IwIvYBjwKXjucAWuUZgplZY60EwhZgnqQuSTOoFn976/r0Akuy5WuBTRERWXtPdhVSFzAPeJrqqaKLJZ2Q1RoWAtsmfjjFRj/crjosMzOrV2nWISKGJS0DNlK9GmhtRGyVtBLoi4he4F7gAUn9VGcGPdm2WyU9DLwADAO3RMR+YLOk9cCzWftzwOrJP7wDKqXq2auRgHLeiSwzs8Q1DQSAiNgAbKhru71meQi4rmDbO4A7ctq/BHzpUAY7EeUsEPbtH6FcKh+pH2tmdsxI5k7l0RmC6whmZvnSCYRy9VB9L4KZWb50AsEzBDOzhpIJhNEawvCI70UwM8uTTCCMzhCG93uGYGaWJ51AyGoIPmVkZpYvnUAYO2XkQDAzy5NMIJTHisquIZiZ5UkmECpjN6Z5hmBmliedQHANwcysoXQCwTUEM7OGkgkE1xDMzBpLJhBcQzAzayydQHANwcysoWQCoewagplZQ8kEQsU1BDOzhpIJhLJrCGZmDSUTCG2uIZiZNZRMILiGYGbWWDKB4BqCmVljyQSCawhmZo21FAiSFknaLqlf0vKcx4+T9FD2+GZJnTWPrcjat0u6qqb9FEnrJf1c0jZJl0zGARWplP0VmmZmjTQNBEll4G7gamA+cIOk+XXdlgJvRcTZwJ3Aqmzb+UAPcA6wCPhWtj+AbwD/GBEfAc4Htk38cIpVStVDdQ3BzCxfKzOEBUB/ROyIiL3AOmBxXZ/FwP3Z8npgoSRl7esi4r2IeBnoBxZImgVcAdwLEBF7I+LtiR9OsbEawn7XEMzM8rQSCHOAnTXrA1lbbp+IGAb2ALMbbHsWMAjcJ+k5SWsknZj3wyXdLKlPUt/g4GALw81XLvsqIzOzRloJBOW01b+rFvUpaq8Avwt8OyIuBH4NHFSbAIiI1RHRHRHd7e3tLQw3nz/+2syssVYCYQCYW7PeAewq6iOpApwMvNlg2wFgICI2Z+3rqQbEYTNaQ3BR2cwsXyuBsAWYJ6lL0gyqReLeuj69wJJs+VpgU0RE1t6TXYXUBcwDno6IfwV2SvqdbJuFwAsTPJaGxmYIvuzUzCxXpVmHiBiWtAzYCJSBtRGxVdJKoC8ieqkWhx+Q1E91ZtCTbbtV0sNU3+yHgVsiYn+26/8KPJiFzA7gTyb52N6nVBKSb0wzMyvSNBAAImIDsKGu7faa5SHguoJt7wDuyGl/Hug+lMFOVKUk9vmUkZlZrmTuVIZqHcE1BDOzfIkFglxDMDMrkFQglMtyDcHMrEBSgeAagplZscQCocR+nzIyM8uVVCCUS/KdymZmBZIKhIprCGZmhZIKhLJrCGZmhZIKhDbXEMzMCiUVCK4hmJkVSyoQXEMwMyuWVCB4hmBmViypQPBHV5iZFUssEPzhdmZmRdIKhLIYdg3BzCxXUoHgGoKZWbGkAsE1BDOzYokFgmsIZmZFkgqEsmsIZmaFkgqESkmeIZiZFUgqEMolsc81BDOzXC0FgqRFkrZL6pe0POfx4yQ9lD2+WVJnzWMrsvbtkq6q264s6TlJP5rogbSizTUEM7NCTQNBUhm4G7gamA/cIGl+XbelwFsRcTZwJ7Aq23Y+0AOcAywCvpXtb9RtwLaJHkSrqjUEB4KZWZ5WZggLgP6I2BERe4F1wOK6PouB+7Pl9cBCScra10XEexHxMtCf7Q9JHcAfAWsmfhitqdYQXFQ2M8vTSiDMAXbWrA9kbbl9ImIY2APMbrLt14G/AI7YO3TZ9yGYmRVqJRCU01b/rlrUJ7dd0ieA1yPimaY/XLpZUp+kvsHBweajbaCtXPIpIzOzAq0EwgAwt2a9A9hV1EdSBTgZeLPBtpcB10h6heopqCslfTfvh0fE6ojojoju9vb2FoZbrOzLTs3MCrUSCFuAeZK6JM2gWiTurevTCyzJlq8FNkVEZO092VVIXcA84OmIWBERHRHRme1vU0R8ehKOp6FKyTemmZkVqTTrEBHDkpYBG4EysDYitkpaCfRFRC9wL/CApH6qM4OebNutkh4GXgCGgVsiYv9hOpamyiUxEjAyEpRKeWezzMzS1TQQACJiA7Chru32muUh4LqCbe8A7miw738C/qmVcUxUW7k6IRoeCWY4EMzM3ie5O5UB1xHMzHIkFQiVLBBcRzAzO1hSgTA6Q/C9CGZmB0sqECo1NQQzM3u/tALBNQQzs0JJBULZNQQzs0JJBULFNQQzs0JJBcKBGYIDwcysXlKBMHpjmmsIZmYHSyoQXEMwMyuWVCD4KiMzs2JJBcLoDGGfi8pmZgdJKhBcQzAzK5ZUILiGYGZWLKlAcA3BzKxYUoHgD7czMyuWVCC0+cPtzMwKJRUIB74gxzUEM7N6SQVCxR9dYWZWKKlAcA3BzKxYUoHgGoKZWbGWAkHSIknbJfVLWp7z+HGSHsoe3yyps+axFVn7dklXZW1zJT0haZukrZJum6wDasQ1BDOzYk0DQVIZuBu4GpgP3CBpfl23pcBbEXE2cCewKtt2PtADnAMsAr6V7W8Y+LOI+ChwMXBLzj4nnWsIZmbFWpkhLAD6I2JHROwF1gGL6/osBu7PltcDCyUpa18XEe9FxMtAP7AgInZHxLMAEfFLYBswZ+KH05hrCGZmxVoJhDnAzpr1AQ5+8x7rExHDwB5gdivbZqeXLgQ2tz7s8am4hmBmVqiVQFBOW/07alGfhttKOgn4B+DzEfFO7g+XbpbUJ6lvcHCwheEWq7iGYGZWqJVAGADm1qx3ALuK+kiqACcDbzbaVlIb1TB4MCIeLfrhEbE6Irojoru9vb2F4RbzV2iamRVrJRC2APMkdUmaQbVI3FvXpxdYki1fC2yKiMjae7KrkLqAecDTWX3hXmBbRPztZBxIKyquIZiZFao06xARw5KWARuBMrA2IrZKWgn0RUQv1Tf3ByT1U50Z9GTbbpX0MPAC1SuLbomI/ZIuB24Cfibp+exH/WVEbJjsA6zlGYKZWbGmgQCQvVFvqGu7vWZ5CLiuYNs7gDvq2p4kv75wWEmiUpJrCGZmOZK6UxmqswTPEMzMDpZcIFRKYr9rCGZmB0kuEDxDMDPLl1wgtJVL/k5lM7McyQVCuSR/p7KZWY7kAqFSku9DMDPLkVwglMuuIZiZ5UkuENpKJQeCmVmO5AKh7BvTzMxyJRkIriGYmR0suUCouIZgZpYrvUBwDcHMLFeCgeAagplZnuQCwTUEM7N8yQWCawhmZvnSCwTXEMzMciUYCK4hmJnlSS4QXEMwM8uXXCC4hmBmli+9QCiV/PHXZmY5EgwE+QtyzMxytBQIkhZJ2i6pX9LynMePk/RQ9vhmSZ01j63I2rdLuqrVfR4u5brvVP7N3v1H6kebmR3VKs06SCoDdwO/DwwAWyT1RsQLNd2WAm9FxNmSeoBVwPWS5gM9wDnAGcD/kvTvs22a7fOwGK0h/HJoH3/zo2081LeTM06eyce7PsjHOz/IFfPaOXP2CYd7GGZmR52mgQAsAPojYgeApHXAYqD2zXsx8N+z5fXANyUpa18XEe8BL0vqz/ZHC/s8LMol8c7QPhZ9/Sfs3vMbbrzoTPb8Zh9PvfQGP3h+FwDzfuskFn70t+n+8Kl86JSZnHHy8ZxyQhvVQzIzm55aCYQ5wM6a9QHgoqI+ETEsaQ8wO2v/v3XbzsmWm+3zsGgrlxjaN8KMSolH/vOlfOzDpwIQEbzyxrts+vnrPL7t31jzkx3c878PnFqqlMSMSqn6r1yiXBIlCQkkqsuAsv8ixtZHjS41KmlHFD86rlK46+dmR47e9x8g51dwnL+TP/78f+C4Snl8G7eolUDI+7O4/pCK+hS159Uucp8mSTcDNwOceeaZxaNs0fUfn8vps2Zy0yUf5oQZBw5fEl2nncjSy7tYenkX7wzt46XXf8XuPUPs3jPEL371HnuHR9g7PMK+/SOMRDASMDISBNU38pFgbDnqjijqDk+5T83Yg+N5qHgbz2zMDrvRP+bGfvdrfu3qfwPH8zvZ8D1jkrQSCAPA3Jr1DmBXQZ8BSRXgZODNJts22ycAEbEaWA3Q3d094b93P3L6LD5y+qym/WbNbOPCM0/lwon+QDOzY0QrVxltAeZJ6pI0g2qRuLeuTy+wJFu+FtgU1bjsBXqyq5C6gHnA0y3u08zMjqCmM4SsJrAM2AiUgbURsVXSSqAvInqBe4EHsqLxm1Tf4Mn6PUy1WDwM3BIR+wHy9jn5h2dmZq1SoyLm0aa7uzv6+vqmehhmZscUSc9ERHezfsndqWxmZvkcCGZmBjgQzMws40AwMzPAgWBmZplj6iojSYPAq+Pc/DTgF5M4nGORnwM/B6kfP6T5HHw4ItqbdTqmAmEiJPW1ctnVdObnwM9B6scPfg4a8SkjMzMDHAhmZpZJKRBWT/UAjgJ+DvwcpH784OegUDI1BDMzayylGYKZmTUw7QNB0iJJ2yX1S1o+1eM5EiTNlfSEpG2Stkq6LWv/oKT/KenF7L+nTvVYDzdJZUnPSfpRtt4laXP2HDyUffz6tCXpFEnrJf08ez1cktLrQNKfZr8D/yzpe5JmpvYaOBTTOhAklYG7gauB+cANkuZP7aiOiGHgzyLio8DFwC3ZcS8HHo+IecDj2fp0dxuwrWZ9FXBn9hy8BSydklEdOd8A/jEiPgKcT/W5SOJ1IGkOcCvQHRHnUv2o/R7Sew20bFoHArAA6I+IHRGxF1gHLJ7iMR12EbE7Ip7Nln9J9U1gDtVjvz/rdj/wyakZ4ZEhqQP4I2BNti7gSmB91mVaPweSZgFXUP2+EiJib0S8TVqvgwpwfPZNjicAu0noNXCopnsgzAF21qwPZG3JkNQJXAhsBn47InZDNTSA35q6kR0RXwf+AhjJ1mcDb0fEcLY+3V8PZwGDwH3ZabM1kk4kkddBRPwL8DXgNapBsAd4hrReA4dkugdC3rdSJ3NZlaSTgH8APh8R70z1eI4kSZ8AXo+IZ2qbc7pO59dDBfhd4NsRcSHwa6bp6aE8WW1kMdAFnAGcSPX0cb3p/Bo4JNM9EAaAuTXrHcCuKRrLESWpjWoYPBgRj2bN/ybpQ9njHwJen6rxHQGXAddIeoXqqcIrqc4YTslOH8D0fz0MAAMRsTlbX081IFJ5Hfwe8HJEDEbEPuBR4FLSeg0ckukeCFuAedlVBTOoFpR6p3hMh112rvxeYFtE/G3NQ73Akmx5CfCDIz22IyUiVkRER0R0Uv3/vikiPgU8AVybdZvuz8G/Ajsl/U7WtJDq95un8jp4DbhY0gnZ78To8SfzGjhU0/7GNEl/SPUvwzKwNiLumOIhHXaSLgd+AvyMA+fP/5JqHeFh4EyqvyzXRcSbUzLII0jSfwT+PCI+IeksqjOGDwLPAZ+OiPemcnyHk6QLqBbVZwA7gD+h+odgEq8DSX8NXE/1yrvngP9EtWaQzGvgUEz7QDAzs9ZM91NGZmbWIgeCmZkBDgQzM8s4EMzMDHAgmJlZxoFgZmaAA8HMzDIOBDMzA+D/A2yMUHJReT1jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps[:94], loss_list, label = 'Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size=1, hidden_size=50, num_layers=2)#(input_size,hidden_size,num_layers)\n",
    "input0 = torch.randn(66, 1, 1)#(seq_len, batch, input_size)\n",
    "h0 = torch.randn(2, 1, 50) #(num_layers,batch,output_size)\n",
    "c0 = torch.randn(2, 1, 50) #(num_layers,batch,output_size)\n",
    "output, (hn, cn) = rnn(input0, (h0, c0))\n",
    "\n",
    "print(output.size())\n",
    "\n",
    "torch.manual_seed(1) \n",
    "\n",
    "\n",
    "def forward(self, x, h_n,h_c):\n",
    "    r_out,  = self.rnn(x, h_state)\n",
    "    r_out = r_out.view(-1, 32)\n",
    "    outs = self.out(r_out)\n",
    "    return outs.view(-1, 10, 1), h_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
